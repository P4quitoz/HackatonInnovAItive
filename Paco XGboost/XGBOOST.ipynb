{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8f9be8b",
   "metadata": {},
   "source": [
    "# First 2 XGBOOST APPROACH WITH DATA RESCALED\n",
    "# BUT NOT SMOOTHED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3685751",
   "metadata": {},
   "source": [
    "This is due to better empirical performences of the sets and visually. \n",
    "But using rolling3 smoothing dataset, and Optimizing better, we believe we would get better results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f4efaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct homes in train: 4\n",
      "Using GroupKFold with n_splits = 4\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[10:49:08] /Users/runner/miniforge3/conda-bld/xgboost-split_1762060257953/work/src/data/data.cc:565: Check failed: valid: Label contains NaN, infinity or a value too large.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000162c84654 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x0000000162e125e0 xgboost::MetaInfo::SetInfoFromHost(xgboost::Context const*, xgboost::StringView, xgboost::Json) + 3260\n  [bt] (2) 3   libxgboost.dylib                    0x0000000162e1180c xgboost::MetaInfo::SetInfo(xgboost::Context const&, xgboost::StringView, xgboost::StringView) + 620\n  [bt] (3) 4   libxgboost.dylib                    0x0000000162c9b28c XGDMatrixSetInfoFromInterface + 236\n  [bt] (4) 5   libffi.8.dylib                      0x00000001021f8050 ffi_call_SYSV + 80\n  [bt] (5) 6   libffi.8.dylib                      0x00000001021f589c ffi_call_int + 1444\n  [bt] (6) 7   _ctypes.cpython-312-darwin.so       0x000000010190c8fc _ctypes_callproc + 1172\n  [bt] (7) 8   _ctypes.cpython-312-darwin.so       0x00000001019062d0 PyCFuncPtr_call + 1244\n  [bt] (8) 9   python3.12                          0x0000000100604860 _PyObject_MakeTpCall + 312\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 97\u001b[39m\n\u001b[32m     85\u001b[39m y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n\u001b[32m     87\u001b[39m model = XGBRegressor(\n\u001b[32m     88\u001b[39m     n_estimators=\u001b[32m300\u001b[39m,\n\u001b[32m     89\u001b[39m     learning_rate=\u001b[32m0.05\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m     95\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m preds_oof[val_idx] = model.predict(X_val)\n\u001b[32m    104\u001b[39m models.append(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:750\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    749\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/sklearn.py:1340\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1337\u001b[39m model, feature_types = get_model_categories(X, model, \u001b[38;5;28mself\u001b[39m.feature_types)\n\u001b[32m   1339\u001b[39m evals_result: EvalsLog = {}\n\u001b[32m-> \u001b[39m\u001b[32m1340\u001b[39m train_dmatrix, evals = \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1349\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1350\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1352\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1360\u001b[39m     obj: Optional[Objective] = _objective_decorator(\u001b[38;5;28mself\u001b[39m.objective)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/sklearn.py:701\u001b[39m, in \u001b[36m_wrap_evaluation_matrices\u001b[39m\u001b[34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[39m\n\u001b[32m    696\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Convert array_like evaluation matrices into DMatrix. Perform sanity checks on the\u001b[39;00m\n\u001b[32m    697\u001b[39m \u001b[33;03mway.\u001b[39;00m\n\u001b[32m    698\u001b[39m \n\u001b[32m    699\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    700\u001b[39m \u001b[38;5;66;03m# Feature_types contains the optional reference categories from the booster object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m train_dmatrix = \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    715\u001b[39m n_validation = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(train_dmatrix, \u001b[33m\"\u001b[39m\u001b[33mget_categories\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/sklearn.py:1254\u001b[39m, in \u001b[36mXGBModel._create_dmatrix\u001b[39m\u001b[34m(self, ref, **kwargs)\u001b[39m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m.tree_method, \u001b[38;5;28mself\u001b[39m.device) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.booster != \u001b[33m\"\u001b[39m\u001b[33mgblinear\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuantileDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_bin\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[32m   1258\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:750\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    749\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:1744\u001b[39m, in \u001b[36mQuantileDMatrix.__init__\u001b[39m\u001b[34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, max_quantile_batches, data_split_mode)\u001b[39m\n\u001b[32m   1724\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1725\u001b[39m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1726\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   (...)\u001b[39m\u001b[32m   1737\u001b[39m         )\n\u001b[32m   1738\u001b[39m     ):\n\u001b[32m   1739\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1740\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIf data iterator is used as input, data like label should be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1741\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mspecified as batch argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1742\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1749\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1750\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1751\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1752\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1753\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1754\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1755\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1756\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1757\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1758\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_quantile_blocks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_quantile_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1759\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:1808\u001b[39m, in \u001b[36mQuantileDMatrix._init\u001b[39m\u001b[34m(self, data, ref, enable_categorical, max_quantile_blocks, **meta)\u001b[39m\n\u001b[32m   1793\u001b[39m config = make_jcargs(\n\u001b[32m   1794\u001b[39m     nthread=\u001b[38;5;28mself\u001b[39m.nthread,\n\u001b[32m   1795\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1796\u001b[39m     max_bin=\u001b[38;5;28mself\u001b[39m.max_bin,\n\u001b[32m   1797\u001b[39m     max_quantile_blocks=max_quantile_blocks,\n\u001b[32m   1798\u001b[39m )\n\u001b[32m   1799\u001b[39m ret = _LIB.XGQuantileDMatrixCreateFromCallback(\n\u001b[32m   1800\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1801\u001b[39m     it.proxy.handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1806\u001b[39m     ctypes.byref(handle),\n\u001b[32m   1807\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1808\u001b[39m \u001b[43mit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1809\u001b[39m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[32m   1810\u001b[39m _check_call(ret)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:593\u001b[39m, in \u001b[36mDataIter.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    591\u001b[39m exc = \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    592\u001b[39m \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:574\u001b[39m, in \u001b[36mDataIter._handle_exception\u001b[39m\u001b[34m(self, fn, dft_ret)\u001b[39m\n\u001b[32m    571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dft_ret\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    576\u001b[39m     \u001b[38;5;66;03m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[32m    577\u001b[39m     \u001b[38;5;66;03m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[32m    578\u001b[39m     \u001b[38;5;66;03m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[32m    579\u001b[39m     tb = sys.exc_info()[\u001b[32m2\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:661\u001b[39m, in \u001b[36mDataIter._next_wrapper.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    659\u001b[39m     \u001b[38;5;28mself\u001b[39m._temporary_data = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    660\u001b[39m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_exception(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m), \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/data.py:1632\u001b[39m, in \u001b[36mSingleBatchInternalIter.next\u001b[39m\u001b[34m(self, input_data)\u001b[39m\n\u001b[32m   1630\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1631\u001b[39m \u001b[38;5;28mself\u001b[39m.it += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1632\u001b[39m \u001b[43minput_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:750\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    749\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:650\u001b[39m, in \u001b[36mDataIter._next_wrapper.<locals>.input_data\u001b[39m\u001b[34m(data, feature_names, feature_types, **kwargs)\u001b[39m\n\u001b[32m    648\u001b[39m \u001b[38;5;28mself\u001b[39m._temporary_data = (new, feature_names, feature_types)\n\u001b[32m    649\u001b[39m dispatch_proxy_set_data(\u001b[38;5;28mself\u001b[39m.proxy, new)\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[38;5;28mself\u001b[39m._data_ref = ref\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:750\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    749\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:1051\u001b[39m, in \u001b[36mDMatrix.set_info\u001b[39m\u001b[34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[39m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch_meta_backend\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mset_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1053\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_weight(weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:1189\u001b[39m, in \u001b[36mDMatrix.set_label\u001b[39m\u001b[34m(self, label)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Set label of dmatrix\u001b[39;00m\n\u001b[32m   1181\u001b[39m \n\u001b[32m   1182\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1185\u001b[39m \u001b[33;03m    The label information to be set into DMatrix\u001b[39;00m\n\u001b[32m   1186\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch_meta_backend\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m \u001b[43mdispatch_meta_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfloat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/data.py:1581\u001b[39m, in \u001b[36mdispatch_meta_backend\u001b[39m\u001b[34m(matrix, data, name, dtype)\u001b[39m\n\u001b[32m   1579\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_series(data):\n\u001b[32m-> \u001b[39m\u001b[32m1581\u001b[39m     \u001b[43m_meta_from_pandas_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1582\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_dlpack(data):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/data.py:731\u001b[39m, in \u001b[36m_meta_from_pandas_series\u001b[39m\u001b[34m(data, name, dtype, handle)\u001b[39m\n\u001b[32m    729\u001b[39m     data = data.to_dense()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data.shape) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m data.shape[\u001b[32m1\u001b[39m] == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m data.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m \u001b[43m_meta_from_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/data.py:1511\u001b[39m, in \u001b[36m_meta_from_numpy\u001b[39m\u001b[34m(data, field, dtype, handle)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMasked array is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1510\u001b[39m interface_str = array_interface(data)\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGDMatrixSetInfoFromInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_Lab/lib/python3.12/site-packages/xgboost/core.py:323\u001b[39m, in \u001b[36m_check_call\u001b[39m\u001b[34m(ret)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    313\u001b[39m \n\u001b[32m    314\u001b[39m \u001b[33;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    return value from API calls\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "\u001b[31mXGBoostError\u001b[39m: [10:49:08] /Users/runner/miniforge3/conda-bld/xgboost-split_1762060257953/work/src/data/data.cc:565: Check failed: valid: Label contains NaN, infinity or a value too large.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000162c84654 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x0000000162e125e0 xgboost::MetaInfo::SetInfoFromHost(xgboost::Context const*, xgboost::StringView, xgboost::Json) + 3260\n  [bt] (2) 3   libxgboost.dylib                    0x0000000162e1180c xgboost::MetaInfo::SetInfo(xgboost::Context const&, xgboost::StringView, xgboost::StringView) + 620\n  [bt] (3) 4   libxgboost.dylib                    0x0000000162c9b28c XGDMatrixSetInfoFromInterface + 236\n  [bt] (4) 5   libffi.8.dylib                      0x00000001021f8050 ffi_call_SYSV + 80\n  [bt] (5) 6   libffi.8.dylib                      0x00000001021f589c ffi_call_int + 1444\n  [bt] (6) 7   _ctypes.cpython-312-darwin.so       0x000000010190c8fc _ctypes_callproc + 1172\n  [bt] (7) 8   _ctypes.cpython-312-darwin.so       0x00000001019062d0 PyCFuncPtr_call + 1244\n  [bt] (8) 9   python3.12                          0x0000000100604860 _PyObject_MakeTpCall + 312\n\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas.api.types as ptypes\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(\"/Users/pacohoche/Desktop/Hackathon Git/HackatonInnovAItive/data/processed/train_1min.csv\")\n",
    "test = pd.read_csv(\"/Users/pacohoche/Desktop/Hackathon Git/HackatonInnovAItive/data/raw/test.csv\")\n",
    "# SORRY, BUT I CANNOT UPLOAD THE DATA FILES TO TEST THE CODE.\n",
    "\n",
    "\n",
    "def make_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # ensure datetime is parsed\n",
    "    if not ptypes.is_datetime64_any_dtype(df[\"datetime\"]):\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "    df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "    df[\"minute\"] = df[\"datetime\"].dt.minute\n",
    "    df[\"dayofweek\"] = df[\"datetime\"].dt.dayofweek\n",
    "\n",
    "    return df\n",
    "\n",
    "def make_window_features(df, window=10, is_train=True):\n",
    "    \"\"\"\n",
    "    Creates lag features for a sliding window of size `window`.\n",
    "    - If `home_id` exists: lags are computed *within each home*.\n",
    "    - Otherwise: lags are computed globally.\n",
    "    Names and dimensions are unchanged.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    if \"home_id\" in df.columns:\n",
    "        # sort by home and time, like before (for both train and test)\n",
    "        df = df.sort_values([\"home_id\", \"datetime\"])\n",
    "        group_power = df.groupby(\"home_id\")[\"power\"]\n",
    "\n",
    "        for lag in range(1, window + 1):\n",
    "            df[f\"lag_{lag}\"] = group_power.shift(lag)\n",
    "    else:\n",
    "        # fallback: no home_id → treat as a single sequence (like your old test path)\n",
    "        df = df.sort_values(\"datetime\")\n",
    "        for lag in range(1, window + 1):\n",
    "            df[f\"lag_{lag}\"] = df[\"power\"].shift(lag)\n",
    "\n",
    "    # Fill initial NaNs with 0 (same as before)\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in range(1, window + 1)]\n",
    "    df[lag_cols] = df[lag_cols].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = make_features(train)\n",
    "test = make_features(test)\n",
    "\n",
    "train = make_window_features(train, window=20, is_train=True)\n",
    "test = make_window_features(test, window=20, is_train=False)\n",
    "\n",
    "\n",
    "FEATURES = [\"power\", \"hour\", \"minute\", \"dayofweek\"] + [f\"lag_{lag}\" for lag in range(1, 21)]\n",
    "X = train[FEATURES]\n",
    "y = train[\"fridge\"]\n",
    "X_test = test[FEATURES]\n",
    "\n",
    "\n",
    "n_groups = train[\"home_id\"].nunique()\n",
    "print(\"Number of distinct homes in train:\", n_groups)\n",
    "\n",
    "models = []\n",
    "\n",
    "if n_groups >= 2:\n",
    "    n_splits = min(10, n_groups)\n",
    "    print(\"Using GroupKFold with n_splits =\", n_splits)\n",
    "\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    preds_oof = np.zeros(len(train))\n",
    "\n",
    "    for tr_idx, val_idx in gkf.split(X, y, groups=train[\"home_id\"]):\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        preds_oof[val_idx] = model.predict(X_val)\n",
    "        models.append(model)\n",
    "\n",
    "    print(\"CV RMSE:\", np.sqrt(mean_squared_error(y, preds_oof)))\n",
    "    print(\"CV MAE:\", mean_absolute_error(y, preds_oof))\n",
    "else:\n",
    "    # These are not enough groups for GroupKFold, technically we wouldn't be able to do CV.\n",
    "    # in fact we just do the regression, but since we talked about replicability. \n",
    "    print(\"Only one group found, training on full data without CV.\")\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    models.append(model)\n",
    "\n",
    "train_viz = train.copy()\n",
    "train_viz[\"pred_fridge\"] = preds_oof\n",
    "\n",
    "# If we have home_id, plot one time-series per house\n",
    "if \"home_id\" in train_viz.columns:\n",
    "    homes = sorted(train_viz[\"home_id\"].unique())\n",
    "else:\n",
    "    homes = [None]\n",
    "\n",
    "for home in homes:\n",
    "    if home is not None:\n",
    "        df_plot = train_viz[train_viz[\"home_id\"] == home].copy()\n",
    "        title = f\"Home {home} — fridge: true vs predicted\"\n",
    "    else:\n",
    "        df_plot = train_viz.copy()\n",
    "        title = \"Fridge — true vs predicted\"\n",
    "\n",
    "    # Sort by time so the curves make sense\n",
    "    df_plot = df_plot.sort_values(\"datetime\")\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(df_plot[\"datetime\"], df_plot[\"fridge\"], label=\"True\")\n",
    "    plt.plot(df_plot[\"datetime\"], df_plot[\"pred_fridge\"], label=\"Predicted\", alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Datetime\")\n",
    "    plt.ylabel(\"Fridge power\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Predictions. \n",
    "test_preds = np.mean([m.predict(X_test) for m in models], axis=0)\n",
    "\n",
    "# Submission Files \n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],   # from your test.csv\n",
    "    \"fridge\": test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_Final.csv\", index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas.api.types as ptypes\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"train_1min.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Remove rows with missing target or power\n",
    "train = train.dropna(subset=[\"power\", \"fridge\"])\n",
    "\n",
    "\n",
    "def make_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure datetime is parsed\n",
    "    if not ptypes.is_datetime64_any_dtype(df[\"datetime\"]):\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "    df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "    df[\"minute\"] = df[\"datetime\"].dt.minute\n",
    "    df[\"dayofweek\"] = df[\"datetime\"].dt.dayofweek\n",
    "    df[\"second\"] = df[\"datetime\"].dt.second\n",
    "\n",
    "    # Is this a quarter-hour reading (00, 15, 30, 45 and second == 0)?\n",
    "    df[\"is_quarter\"] = ((df[\"minute\"] % 15 == 0) & (df[\"second\"] == 0)).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_sequence_features_train(df):\n",
    "    df = df.sort_values([\"home_id\", \"datetime\"]).copy()\n",
    "\n",
    "    # previous power within each home\n",
    "    df[\"prev_power\"] = df.groupby(\"home_id\")[\"power\"].shift(1)\n",
    "\n",
    "    # difference to previous measurement\n",
    "    df[\"delta_power\"] = df[\"power\"] - df[\"prev_power\"]\n",
    "\n",
    "    # Fill NaNs for the first row of each group\n",
    "    df[[\"prev_power\", \"delta_power\"]] = df[[\"prev_power\", \"delta_power\"]].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_sequence_features_test(df):\n",
    "    # test is a single household → treat as one sequence\n",
    "    df = df.sort_values(\"datetime\").copy()\n",
    "\n",
    "    df[\"prev_power\"] = df[\"power\"].shift(1)\n",
    "    df[\"delta_power\"] = df[\"power\"] - df[\"prev_power\"]\n",
    "    df[[\"prev_power\", \"delta_power\"]] = df[[\"prev_power\", \"delta_power\"]].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply feature engineering\n",
    "train = make_features(train)\n",
    "test = make_features(test)\n",
    "\n",
    "train = add_sequence_features_train(train)\n",
    "test = add_sequence_features_test(test)\n",
    "\n",
    "# Features\n",
    "\n",
    "FEATURES = [\n",
    "    \"power\",\n",
    "    \"hour\",\n",
    "    \"minute\",\n",
    "    \"dayofweek\",\n",
    "    \"is_quarter\",\n",
    "    \"prev_power\",\n",
    "    \"delta_power\",\n",
    "]\n",
    "\n",
    "X = train[FEATURES]\n",
    "y = train[\"fridge\"]\n",
    "X_test = test[FEATURES]\n",
    "\n",
    "\n",
    "n_groups = train[\"home_id\"].nunique()\n",
    "print(\"Number of distinct homes in train:\", n_groups)\n",
    "\n",
    "models = []  # will store (model, scaler)\n",
    "\n",
    "if n_groups >= 2:\n",
    "    n_splits = min(5, n_groups)\n",
    "    print(\"Using GroupKFold with n_splits =\", n_splits)\n",
    "\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    preds_oof = np.zeros(len(train))\n",
    "\n",
    "    for tr_idx, val_idx in gkf.split(X, y, groups=train[\"home_id\"]):\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "        # --- Scaling per fold ---\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_scaled = scaler.fit_transform(X_tr)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_tr_scaled, y_tr,\n",
    "            eval_set=[(X_val_scaled, y_val)],\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        preds_oof[val_idx] = model.predict(X_val_scaled)\n",
    "        models.append((model, scaler))  # store model + its scaler\n",
    "\n",
    "    print(\"CV RMSE:\", np.sqrt(mean_squared_error(y, preds_oof)))\n",
    "    print(\"CV MAE:\", mean_absolute_error(y, preds_oof))\n",
    "else:\n",
    "    # only one home_id available → just train one model on all data\n",
    "    print(\"Only one group found, training on full data without CV.\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "    )\n",
    "    model.fit(X_scaled, y)\n",
    "    models.append((model, scaler))\n",
    "\n",
    "\n",
    "\n",
    "# Plots \n",
    "\n",
    "train_viz = train.copy()\n",
    "train_viz[\"pred_fridge\"] = preds_oof\n",
    "\n",
    "# If we have home_id, plot one time-series per house\n",
    "if \"home_id\" in train_viz.columns:\n",
    "    homes = sorted(train_viz[\"home_id\"].unique())\n",
    "else:\n",
    "    homes = [None]\n",
    "\n",
    "for home in homes:\n",
    "    if home is not None:\n",
    "        df_plot = train_viz[train_viz[\"home_id\"] == home].copy()\n",
    "        title = f\"Home {home} — fridge: true vs predicted\"\n",
    "    else:\n",
    "        df_plot = train_viz.copy()\n",
    "        title = \"Fridge — true vs predicted\"\n",
    "\n",
    "    # Sort by time so the curves make sense\n",
    "    df_plot = df_plot.sort_values(\"datetime\")\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(df_plot[\"datetime\"], df_plot[\"fridge\"], label=\"True\")\n",
    "    plt.plot(df_plot[\"datetime\"], df_plot[\"pred_fridge\"], label=\"Predicted\", alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Datetime\")\n",
    "    plt.ylabel(\"Fridge power\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "test_preds = np.mean(\n",
    "    [m.predict(s.transform(X_test)) for (m, s) in models],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"fridge\": test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c9f60c",
   "metadata": {},
   "source": [
    "## Comments on the plots\n",
    "\n",
    "Even tho we have a worst MAE on the CV, we have less overfitting on the plot. \n",
    "We can see mostly when the total_power is 0, in the previous plots it was still having the fridge in activity, now it's better. \n",
    "This is trying with the data not smoothed, so the train_1min.csv file "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
