Machine Learning Energy Disaggregation â€“ Fridge Prediction Hackathon

This repository contains our full pipeline for the Machine Learning Energy Challenge hackathon.
The task is to reconstruct the fridge power consumption from aggregated household smart-meter data based on the Chain2 transmission protocol.

We focus on clean structure, reproducibility, and a common preprocessing layer so that multiple teammates can experiment independently without breaking each other's pipelines.

ğŸ“ Project Structure
hackaton/
â”œâ”€ data/
â”‚  â”œâ”€ raw/
â”‚  â”‚  â”œâ”€ train.csv
â”‚  â”‚  â””â”€ test.csv
â”‚  â””â”€ processed/
â”‚     â”œâ”€ train_1min.csv
â”‚     â”œâ”€ test_1min.csv
â”‚     â”œâ”€ train_features.parquet
â”‚     â””â”€ test_features.parquet
â”‚
â”œâ”€ src/
â”‚  â”œâ”€ common/                 # Shared pipeline used by ALL models
â”‚  â”‚  â”œâ”€ config.py            # global paths & constants
â”‚  â”‚  â”œâ”€ resampling.py        # Chain2 â†’ 1-minute preprocessing
â”‚  â”‚  â”œâ”€ features.py          # feature engineering for ML models
â”‚  â”‚  â””â”€ evaluation.py        # metrics, plots, CV helpers
â”‚  â”‚
â”‚  â”œâ”€ datasets/
â”‚  â”‚  â”œâ”€ make_train.py        # builds processed training dataset
â”‚  â”‚  â”œâ”€ make_test.py         # builds processed test dataset
â”‚  â”‚  â””â”€ (optional) cli.py    # run full pipeline from command line
â”‚  â”‚
â”‚  â”œâ”€ experiments/            # each teammate/model has its own folder
â”‚  â”‚  â”œâ”€ tudor_lgbm/
â”‚  â”‚  â”‚  â”œâ”€ train.py
â”‚  â”‚  â”‚  â”œâ”€ predict.py
â”‚  â”‚  â”‚  â””â”€ config.py
â”‚  â”‚  â”œâ”€ alice_cnn/
â”‚  â”‚  â”œâ”€ bob_baseline/
â”‚  â”‚  â””â”€ ...
â”‚  â”‚
â”‚  â””â”€ utils/
â”‚     â””â”€ logging.py
â”‚
â”œâ”€ models/                    # Saved artifacts per experiment
â”‚  â”œâ”€ tudor_lgbm/
â”‚  â”‚  â””â”€ model.pkl
â”‚  â”œâ”€ alice_cnn/
â”‚  â”‚  â””â”€ model.pt
â”‚  â””â”€ bob_baseline/
â”‚     â””â”€ model.pkl
â”‚
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_eda.ipynb            # exploratory data analysis
â”‚  â””â”€ 02_signal_plots.ipynb   # visualization helpers
â”‚
â”œâ”€ submission/
â”‚  â”œâ”€ tudor_lgbm.csv
â”‚  â”œâ”€ alice_cnn.csv
â”‚  â””â”€ bob_baseline.csv
â”‚
â”œâ”€ requirements.txt
â””â”€ README.md

ğŸš€ What This Project Does
âœ“ Resamples irregular Chain2 smart-meter data

The raw data has variable sampling intervals (15-minute mandatory samples + additional samples every 300W threshold crossing).
We normalize everything to a regular 1-minute grid using a zero-order hold strategy.

âœ“ Adds consistent ML features

All models share the same standardized feature set:

Lag features (1, 2, 5, 10, 30, 60 mins)

Rolling means / stds

Power gradients

Time-of-day features (hour_sin, hour_cos, day-of-week)

Cleaned fridge target

âœ“ Supports multiple independent ML models

Every teammate has their own folder under src/experiments/ and can:

train their own model

tune hyperparameters

generate predictions

save results separately

No one overwrites anyone elseâ€™s work.

ğŸ› ï¸ Setup
Clone the repo
git clone <repo-url>
cd hackaton

Install dependencies
pip install -r requirements.txt

ğŸ“¦ Preprocessing Pipeline
1. Build training dataset
python -m src.datasets.make_train


This:

loads data/raw/train.csv

resamples it to 1-minute resolution (per home)

builds standardized features

saves results to data/processed/

2. Build test dataset
python -m src.datasets.make_test

ğŸ§  Training Your Model

Each person's model lives in src/experiments/<your_model>/.

Example:

python -m src.experiments.tudor_lgbm.train


This:

loads the processed training features

trains the model

performs validation

saves the trained model to models/tudor_lgbm/model.pkl

ğŸ“ˆ Making Predictions

Each model folder contains a predict.py script:

python -m src.experiments.tudor_lgbm.predict


This will:

load processed test features

apply the model

generate a submission file under submission/

ğŸ‘¥ Adding a New Model (Team Workflow)

To add your own model:

Create a folder under:

src/experiments/<your_name_or_model>/


Add:

train.py

predict.py

config.py (optional)

Your code will automatically benefit from:

shared preprocessing

consistent feature engineering

clean data structure

This keeps the project clean, scalable, and easy for multiple contributors.

ğŸ“¬ Final Submission

Your final submission should be placed here:

submission/<your_model_name>.csv


Format must follow the hackathonâ€™s expected output.

ğŸ¤ Contributing

If you want to add improvements to the shared preprocessing pipeline:

open a PR

or discuss with the team
since it affects all experiments.
